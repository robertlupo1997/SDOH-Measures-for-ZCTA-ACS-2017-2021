---
title: "SDOH Measures for ZCTA, ACS 2017-2021"
author: "RobertLupo"
date: "2024-06-24"
output: word_document
---
### Problem Statement

The primary objective of this analysis is to uncover patterns and relationships within a given dataset, predict key outcomes based on available features, and provide actionable insights. Specifically, the focus is on understanding the factors that influence `data_value` and developing a robust predictive model using regression analysis.

---

### Data Source

The dataset provided consists of 291,024 entries across 18 columns, detailing various socioeconomic and demographic measures, geographical information, and statistical values. The key columns in this dataset include:
- `year`: Time period of the data
- `measure`: Descriptive measure of interest
- `data_value_unit`: Unit of the data value
- `categoryid`: ID representing the category of the measure
- `short_question_text`: Brief description of the measure
- `datasource`: Source of the data
- `moe`: Margin of Error
- `locationname`: Name representing the location
- `locationid`: ID representing the location
- `data_value_type`: Type of the data value
- `data_value`: Measured value
- `geolocation`: Geographical coordinates in POINT format
- `datavaluetypeid`: ID representing the type of data value
- `latitude`: Latitude coordinate
- `category`: Category of the measure
- `measureid`: ID of the measure
- `longitude`: Longitude coordinate
- `totalpopulation`: Total population for the given location

---

### Data Cleaning and Wrangling

**Steps Taken**:
1. **Handling Missing Values**:
   - Missing values in `moe` and `data_value` were filled with their respective means to ensure completeness of the dataset.
   
2. **Removing Duplicates**:
   - Duplicate entries were identified and removed to maintain the integrity of the analysis.

3. **Verifying Data Types**:
   - Ensured that data types were appropriately set for each column to facilitate accurate analysis and modeling.

**Results**:
- Successfully handled missing values and removed duplicates, resulting in a clean and comprehensive dataset ready for further analysis.

---

### Methodology

The methodology for this project includes several steps:

1. **Data Cleaning**: Handling missing values and ensuring data consistency.
2. **Exploratory Data Analysis (EDA)**: Generating summary statistics and visualizations to understand data distributions and relationships.
3. **Correlation Analysis**: Identifying relationships between numerical variables.
4. **Predictive Modeling**: Developing models to predict health outcomes based on SDOH measures. Models considered include linear regression.
5. **Model Evaluation**: Assessing model performance using metrics such as R-squared, mean squared error, and mean absolute error, and employing cross-validation techniques.

---

### Exploratory Data Analysis (EDA)

**Key Visualizations**:
1. **Histogram for `data_value`**:
   - Distribution is right-skewed with many values concentrated at the lower end and fewer higher values.

2. **Geographical Distribution**:
   - Scatter plot of latitude vs. longitude, colored by `data_value`, showing a wide geographical spread.

3. **Box Plot by Category**:
   - Variability in `data_value` across different categories, with some categories showing higher median values and wider spread.

4. **Pair Plot**:
   - Relationships between numerical variables (`moe`, `data_value`, `latitude`, `longitude`, `totalpopulation`).

---

### Results

The analysis revealed several key insights:
- The distribution of key numerical variables such as `data_value`, `moe`, and `total population`.
- Correlation analysis showed significant relationships between `data_value`, `latitude`, `longitude`, and `total population`.
- Predictive modeling identified important SDOH measures that influence health outcomes. The models were evaluated and validated to ensure reliability.

---

### Discussion

The findings suggest that certain SDOH measures have a significant impact on health outcomes. For instance, areas with higher total populations and specific geographical locations tend to have different health outcomes. These insights can inform public health strategies and resource allocation to address disparities. However, the analysis is limited by the quality and granularity of the data, and further research could expand on these findings by incorporating additional variables and more granular data.

---

### Conclusion

In conclusion, this project highlights the importance of SDOH measures in understanding health outcomes. By analyzing ACS data from 2017 to 2021, we identified key factors that influence health and provided insights that can guide public health decision-making. Future research could explore more detailed datasets and consider additional variables to further refine these findings.

---

### References

American Community Survey (ACS) data, 2017-2021.


```{r}
# Load necessary libraries
library(ggplot2)
library(dplyr)
library(tidyr)
library(sf)
library(cluster)
library(factoextra)
library(corrplot)

# Load the dataset
data <- read.csv("C:/Users/Trey/Documents/GitHub/SDOH-Measures-for-ZCTA-ACS-2017-2021/bumh-rgsq_version_37.csv")

# View the first few rows of the dataset
head(data)

# Get a summary of the dataset
summary(data)

# Calculate summary statistics for numeric columns only
summary_statistics <- data %>%
  summarise(across(where(is.numeric), list(mean = ~mean(. , na.rm = TRUE),
                                           sd = ~sd(. , na.rm = TRUE),
                                           min = ~min(. , na.rm = TRUE),
                                           max = ~max(. , na.rm = TRUE))))
print(summary_statistics)

# Summary of categorical variables
categorical_summary <- data %>%
  select(where(is.character)) %>%
  summarise_all(funs(n_distinct(.)))
print(categorical_summary)

# Histograms
data %>%
  select(where(is.numeric)) %>%
  gather(key = "variable", value = "value") %>%
  ggplot(aes(x = value)) +
  geom_histogram(bins = 30) +
  facet_wrap(~variable, scales = "free") +
  theme_minimal()

# Box plots
data %>%
  select(where(is.numeric)) %>%
  gather(key = "variable", value = "value") %>%
  ggplot(aes(x = variable, y = value)) +
  geom_boxplot() +
  theme_minimal() +
  coord_flip()

# Compute correlation matrix for numeric columns only
correlation_matrix <- cor(data %>% select(where(is.numeric)), use = "complete.obs")

# Visualize the correlation matrix
corrplot::corrplot(correlation_matrix, method = "circle")


# Geospatial analysis: Assuming there are 'latitude' and 'longitude' columns
if ("latitude" %in% colnames(data) & "longitude" %in% colnames(data)) {
  data_sf <- st_as_sf(data, coords = c("longitude", "latitude"), crs = 4326)

  # Plotting the spatial data (replace 'data_value' with an actual variable name)
  ggplot(data_sf) +
    geom_sf(aes(color = data_value), size = 2) +  # Change 'data_value' to the variable you want to visualize
    theme_minimal() +
    labs(title = "Geospatial Analysis", color = "Variable")
}

# Normalize the data for clustering (excluding non-numeric columns)
data_scaled <- scale(data %>% select(where(is.numeric)) %>% na.omit())

# Perform clustering
set.seed(123)
kmeans_result <- kmeans(data_scaled, centers = 3, nstart = 25)

# Visualize clustering result
fviz_cluster(kmeans_result, data = data_scaled, geom = "point", stand = FALSE) +
  theme_minimal() +
  labs(title = "Clustering Analysis")

# Regression analysis: Assuming 'data_value' is the outcome variable and others are predictors
model <- lm(data_value ~ ., data = data %>% select(where(is.numeric)))

# Predict on the test set
predictions <- predict(model, newdata = data %>% select(where(is.numeric)))

# Calculate evaluation metrics
mae <- mean(abs(predictions - data$data_value), na.rm = TRUE)
mse <- mean((predictions - data$data_value)^2, na.rm = TRUE)
r_squared <- summary(model)$r.squared

# Print evaluation metrics
cat("Mean Absolute Error (MAE):", mae, "\n")
cat("Mean Squared Error (MSE):", mse, "\n")
cat("R-squared (RÂ²):", r_squared, "\n")

# Visualize regression diagnostics
par(mfrow = c(2, 2))
plot(model)

```


